## 1 神经网络

### 1.1 什么是人工神经网络

#### 1.1.1 神经元

加权和 + 激活函数（非线性）

![[Pasted image 20250504113440.png]]

#### 1.1.2 神经网络构成

输入层（数据）、隐藏层（加权和 + 激活）、输出层（目标（加权和））

![[Pasted image 20250504113542.png]]

#### 1.1.3 神经网络参数和超参数

参数：weight、bias

超参数：隐藏层的层数、每一个隐藏层的神经元个数

### 1.2 常见的激活函数

激活函数用于**对每层的输出数据进行变换**，进而为整个网络注入了**非线性因素**。此时，神经网络就可以拟合各种曲线。

- 没有引入非线性因素的网络等价于使用一个线性模型来拟合。
- 通过给网络输出增加激活函数，实现引入非线性因素，是的网络模型可以逼近任意函数，提升网络对复杂问题的拟合能力。

#### 1.2.1 sigmoid 激活函数

$$
f(x) = \frac{1}{1 + e^{-x}}
$$

![[Pasted image 20250504131757.png]]

但是 sigmoid 激活函数有一个问题：因为在梯度下降中，是根据导数来更新权重的，而 sigmoid 激活函数（加权和取值）在 -6 到 6 之外的区间导数就几乎为 0 了，weight 就无法更新了。这就导致：不能在隐藏层中使用，否则很容易出现梯度为 0 的情况，即梯度消失（梯度弥散）现象。那如果我每次将加权和的取值做到 0 附近，就不会有梯度消失现象了，但是，随之而来的问题是：此时 sigmoid 的导数为 0.25，而我进行反向传播是一层一层传播，那么当隐藏层层数超过 5 的话，就没有办法训练了。

sigmoid 激活函数可以在**二分类任务的输出层**进行使用。

![[Pasted image 20250504133005.png]]

#### 1.2.2 tanh 激活函数

$$
f(x) = \frac{1 - e^{-2x}}{1 + e^{-2x}}
$$

![[Pasted image 20250504133919.png]]

隐藏层中要使用指数型激活函数时，就选择 tanh，不要使用 sigmoid。

![[Pasted image 20250504134242.png]]

#### 1.2.3 ReLU 激活函数

$$
f (x) = \max{(0, x)}
$$

![[Pasted image 20250504134757.png]]

- 大于 0：不会梯度消失
- 小于 0：
	- 当某一部分神经元输出为 0，神经元死亡，降低神经网络复杂度，缓解过拟合
	- 当大部分神经元输出为 0，从头开始或换激活函数（leakrelu）

![[Pasted image 20250504135249.png]]

#### 1.2.4 SoftMax 激活函数

- 回归任务：输出层：要输出几个值就有几个神经元，回归任务输出层没有激活（identity 恒等激活）。
- 分类任务：
	- 二分类：输出层：一个神经元，输出的是概率值。用 sigmoid 激活函数。
	- 多分类：输出层：类别个数个神经元，输出的是每一个神经元属于该类别的概率值，概率值和为 1，概率值最大的就对应着分类结果，目标值是热编码的结果，比如为 2，则为 0010。用 softmax 激活函数。

softmax 用于多分类过程中，是二分类函数 sigmoid 在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。

$$
\text{softmax}(z_i) = \frac{e^{z_i}}{\sum_j e^{z_j}}
$$

参数 zi 是输出层神经元的加权和

![[Pasted image 20250504140941.png]]

#### 1.2.5 汇总

- 对于隐藏层：
	- 优先选择 ReLU 激活函数
	- 如果 ReLU 效果不好，那么尝试其他激活，如 Leaky ReLU 等
	- 如果使用了 ReLU，需要注意 Dead ReLU 问题，避免出现大的梯度从而导致过多的神经元死亡
	- 少使用 sigmoid 激活函数，可以尝试使用 tanh 函数
- 对于输出层：
	- 二分类问题选择 sigmoid 激活函数
	- 多分类问题选择 softmax 激活函数
	- 回归问题选择 identity 激活函数

![[Pasted image 20250504142039.png]]

### 1.3 常见的参数初始化方法

### 1.4 神经网络模型的搭建

在 pytorch 中定义深度学习神经网络其实就是层堆叠的过程，继承自 nn. Module，实现两个方法：

- `__init__` 方法中定义网络中的层结构，主要是全连接层，并进行初始化
- `forward` 方法，在实例化模型的时候，底层会自动调用该函数。该函数中可以定义学习率，为初始化定义的 layer 传入数据等。

### 1.5 神经网络模型参数的计算方法

## 2 损失函数

在深度学习中，损失函数是用来衡量模型参数的质量的函数，衡量方式是比价网络输出和真实输出的差异。

损失函数在不同文献中名称是不一样的，主要有以下几种命名方式：

- 损失函数 loss function
- 代价函数 cost function
- 目标函数 objective function
- 误差函数 error function

### 2.1 分类任务的损失函数

#### 2.1.1 多分类损失函数

在多分类任务中，通常使用 softmax 激活函数将 logits 转换为概率的形式，所以**多分类的交叉熵损失**也叫做 **softmax 损失**。注意，什么样的激活对应什么样的损失，不可以前面用 sigmoid 激活，后面用多分类的交叉熵损失。多分类的交叉熵损失前面必须要用 softmax 激活。

$$
L = -\sum_{i=1}^{n} y_i \log(S(f_\theta(x_i)))
$$

- y 是样本 x 属于某一个类别的真实概率（one-hot）
- f(x) 是样本属于某一个类别的预测分数（整个神经网络的输出层的加权和 logits/scores）
- S 是 softmax 激活函数，将属于某一类别的预测分数转换成概率（神经网络预测的结果：概率值 y_hat）
- L 是损失，用来衡量真实值 y 与预测值 f(x) 之间差异性的损失结果

![[Pasted image 20250504172743.png]]

![[Pasted image 20250504173156.png]]

#### 2.1.2 二分类损失函数

在处理二分类任务时，我们不再使用 softmax 激活函数，而是使用 sigmoid 激活函数，那损失函数也相应地进行调整，使用二分类的交叉熵损失函数。

$$
L = - y \log \hat{y} - (1 - y) \log (1 - \hat{y})
$$

- y 是样本 x 属于某一个类别的真实概率
- y^ 是样本属于某一个类别的预测概率
- L 用来衡量真实值 y 与预测值 y^之间差异性的损失结果

### 2.2 回归任务的损失函数

距离度量的那些方法都可以用来衡量连续值之间的差异。

#### 2.2.1 MAE 损失函数

Mean absolute loss（MAE）也被称为 L1 Loss，或曼哈顿距离，是以绝对误差作为距离。

$$
L = \frac{1}{n} \sum_{i=1}^n |y_i - f_\theta(x_i)|
$$

- 分类任务的激活函数是恒等激活，也就是相当于没有激活，因此为 f(x)
- 由于 L1 loss 具有稀疏性，为了惩罚较大的值，因此尝尝将其作为正则项添加到其他 loss 中作为约束
- L1 loss 的最大问题是梯度在零点不平滑，导致会跳过极小值

#### 2.2.2 MSE 损失函数

Mean Squared Loss/Quadratic Loss（MSE loss）也被称为 L2 loss，或欧式距离，是以误差的平方和的均值作为距离。

$$
L = \frac{1}{n} \sum_{i=1}^n (y_i - f_\theta(x_i))^2
$$

- L2 loss 也常常作为正则项
- 当预测值与目标值相差很大时，容易梯度爆炸，太大导致 NaN

#### 2.2.3 smooth L1 损失函数

smooth L1 说的是光滑之后的 L1。

$$
\text{smooth}_{L_1}(x) = \begin{cases} 0.5x^2 & \text{if } |x|<1 \\ |x|-0.5 & \text{else} \end{cases}，
$$

 其中，$x = f(x) - y$ 为真实值和预测值的差值。

该函数实际上就是一个分段函数：

- 在 `[-1, 1]` 之间就是 L2 损失，这样解决了 L1 不光滑的问题
- 在 `[-1, 1]` 之外就是 L1 损失，这样解决了 L2 离群点梯度爆炸的问题

![[Pasted image 20250504184031.png]]

## 3 网络优化方法

### 3.1 梯度下降算法

[[03-线性回归#2.4 梯度下降法]]

### 3.2 梯度下降的优化方法

#### 3.2.1 梯度下降的问题

梯度下降可能遇到的问题：

- **平缓区域**
	- 梯度值较小
	- 导致参数优化速度变慢
- **鞍点问题**
	- 梯度值为 0
	- 参数更新停滞
- **局部最小值**（目前无法优化）
	- 梯度为 0
	- 但参数不是全局最优解

![[Pasted image 20250504223807.png]]

针对上述问题，发展出多种优化方法：

- **Momentum**（动量法）
- **AdaGrad**（自适应梯度）
- **RMSprop**
- **Adam**（自适应矩估计）

这些优化算法通过不同方式改进基础梯度下降，解决收敛速度慢、鞍点停滞等问题。而局部最小值问题目前无法优化。

#### 3.2.2 一个求平均的方法 - 指数加权平均

**指数移动加权平均**则是参考各数值，并且各数值的权重都不同，距离越远的数字对平均数计算的贡献就越小（权重较小），距离越近则对平均数的计算贡献就越大（权重越大）。

比如：明天气温怎么样，和昨天气温有很大关系，而和一个月前的气温关系就小一些。

计算公式可以用下面的式子来表示：

$$
S_t = \begin{cases} Y_1, & t = 1 \\ \beta \cdot S_{t-1} + (1 - \beta) \cdot Y_t, & t > 1 \end{cases}
$$

- $S_t$ 表示指数加权平均值；
- $Y_t$ 表示 t 时刻的值；
- $\beta$ 调节权重系数，该值越大平均数越平缓。

比如：

- t=1 时，$s_1 = y_1$（初始值直接取第一个观测值）
- t=2 时，$s_2 = \beta y_1 + (1-\beta)y_2$（第一个加权平均，包含当前值和上期值）
- t=3 时，$s_3 = \beta^2 y_1 + \beta y_2 - \beta^2 y_2 + (1-\beta)y_3$（展开后可见包含历史值的指数衰减权重）
- …
- $\beta$ 是衰减系数 (0 < $\beta$ < 1)
- 随着时间推移，早期观测值的权重按 $\beta$ 的幂次衰减
- 当前时刻的观测值始终获得最大权重 $(1-\beta)$

#### 3.2.3 优化方法

##### 3.2.3.1 Momentum 动量算法

$$
D_t = \beta \cdot S_{t-1} + (1-\beta) \cdot W_t
$$

- $S_{t-1}$：历史梯度移动加权平均值
- $W_t$：当前时刻的梯度值
- $D_t$：当前时刻的指数加权平均梯度值
- $\beta$：权重系数（0 < $\beta$ < 1）

计算示例（设 $\beta=0.9$）

- 第一次梯度值： $s_1 = d_1 = w_1$（初始值直接取第一个梯度值）
- 第二次梯度值： $d_2 = s_2 = 0.9 \cdot s_1 + 0.1 \cdot w_2$
- 第三次梯度值：$d_3 = s_3 = 0.9 \cdot s_2 + 0.1 \cdot w_3$
- 第四次梯度值：$d_4 = s_4 = 0.9 \cdot s_3 + 0.1 \cdot w_4$

梯度下降公式中梯度的计算，就不再是当前时刻 t 的梯度值，而是历史梯度值的指数移动加权平均值。公式修改为：

$$
W_{t+1} = W_t - \alpha \cdot D_t
$$

- 平缓区域问题：
	- 问题本质：在损失函数平缓区域，传统梯度下降因当前梯度 $W_t$ 过小而更新缓慢。
	- 改善原理：指数加权平均 $D_t$ 会累积历史梯度信息。即使当前梯度 $W_t$ 很小，历史梯度 $S_{t-1}$ 的贡献仍能维持有效更新。动量效应使参数在平缓区保持更新惯性
- 鞍点问题：
	- 问题本质：传统梯度下降在梯度 $W_t=0$ 时完全停滞
	- 改善原理：当 $W_t=0$ 时，$D_t = \beta S_{t-1}$ 仍包含历史梯度信息。历史动量可能帮助逃离鞍点。特别结合 RMSprop 等自适应方法时效果更佳
- 推荐 $\beta=0.9$（保持 90% 历史信息）
- 学习率 $\alpha$ 需相应调小（约为原值的 $1/(1-\beta)$ 倍），不过也可以保持原本的，比如 0.01
- 可与自适应方法（Adam 等）组合使用

##### 3.2.3.2 AdaGrad 自适应梯度

AdaGrad 通过对不同的参数分量使用不同的学习率，AdaGrad 的学习率总体会逐渐减小。

其计算步骤如下：

1. 初始化学习率 $\alpha$、初始化参数 $\theta$、小常数 $\sigma = 1e-6$（防止分母为 0）
2. 初始化梯度累积变量 $s = 0$
3. 从训练集中采样 m 个样本的小批量，计算梯度 $g$
4. 累积平方梯度 $s = s + g \odot g$，表示各个分量相乘

学习率 $\alpha$ 的计算公式如下：

$$
\alpha = \frac{\alpha}{\sqrt{s} + \sigma}
$$

参数更新公式如下：

$$
\theta = \theta - \frac{\alpha}{\sqrt{s} + \sigma} \cdot g
$$

重复 2-4 步骤，即可完成网络训练。

AdaGrad 缺点是可能会使得学习率过早过量地降低，导致模型训练后期学习率太小，较难找到最优解。下面这个将会优化。

##### 3.2.3.3 RMSProp

RMSProp 优化算法是对 AdaGrad 的优化。最主要的不同是，其使用**指数移动加权平均梯度**替换历史梯度的平方和。其计算过程如下：

1. 初始化学习率 $\alpha$、初始化参数 $\theta$、小常数 $\sigma = 1e-6$
2. 初始化参数 $\theta$
3. 初始化梯度累计变量 $s$
4. 从训练集中采样 $m$ 个样本的小批量，计算梯度 $g$
5. 使用指数移动平均累积历史梯度：$s = \beta \cdot s + (1 - \beta)g \odot g$

学习率 $\alpha$ 的计算公式如下：

$$
\alpha = \frac{\alpha}{\sqrt{s} + \sigma}
$$

参数更新公式如下：

$$
\theta = \theta - \frac{\alpha}{\sqrt{s} + \sigma} \cdot g
$$

- AdaGrad 的 $s$ 会单调递增 → 学习率持续下降
- RMSProp 的 $s$ 是加权平均 → 学习率可稳定在一定水平

##### 3.2.3.4 Adam 自适应矩估计

- Momentum 使用指数加权平均计算当前的梯度值
- AdaGrad、RMSProp 使用自适应的学习率
- Adam 优化算法（Adaptive Moment Estimation，自适应矩估计）将 Momentum 和 RMSProp 算法结合在一起。
	- 修正梯度：使用梯度的指数加权平均（有一个 $\beta$）
	- 修正学习率：使用梯度平方的指数加权平均（有一个 $\beta$）

##### 3.2.3.5 总结

- 动量法（使用最多）
	- 优化梯度 -》使用梯度的指数加权平均
	- 使用最多 + 学习率衰减策略（见下面小节）
- AdaGrad （知道）
	- 优化学习率 -》使用梯度平方和，随着迭代次数的增加减小
	- 学习率下降过快
- RMSProp
	- 优化学习率 -》使用梯度平方的指数加权平均，随着迭代次数的增加减小
- Adam
	- 动量 +RMSProp
	- 优化梯度 -》使用梯度的指数加权平均
	- 优化学习率 -》使用梯度平方的指数加权平均，随着迭代次数的增加减小
	- 当你对网络任务不熟悉的时候，可以选择

### 3.3 学习率优化策略

#### 3.3.1 等间隔学习率衰减

```python
lr_scheduler.StepLR(optimizer, step_size, gamma=0.1)

# 功能：等间隔调整学习率  

# 参数：
#   step_size：调整间隔数（例如：50）
#   gamma：调整系数（例如：0.5）  

# 调整方式：  
# 学习率按公式 lr = lr * gamma 进行衰减
```

![[Pasted image 20250504234555.png]]

#### 3.3.2 指定间隔学习率衰减

使用较多

```python
lr_scheduler.MultiStepLR(optimizer, milestones, gamma=0.1)

# 功能：按指定间隔调整学习率

# 主要参数：
#   milestones：设定调整轮次列表（例如：[50, 125, 160]）
#   gamma：调整系数（默认0.1）

# 调整方式：
# 当训练轮数达到milestones中的数值时，学习率按 lr = lr * gamma 进行衰减
```

![[Pasted image 20250504235223.png]]

## 4 正则化方法

### 4.1 正则化的作用

神经网络的强大的表示能力经常遇到过拟合，所以需要使用不同形式的正则化策略。目前在深度学习中使用较多的策略有：范数惩罚（在损失函数后面加上 L1、L2）、DropOut（随机失活）、特殊的网络层（BN 层）等。

### 4.2 DropOut 随机失活策略

在训练神经网络中模型参数较多，在数据量不足的情况下，很容易过拟合。Dropout（随机失活）是一个简单有效的正则化方法。

- 在训练过程中，Dropout 的实现是让神经元以超参数 p 的概率停止工作或者激活被置为 0（并不是每一层有 p% 个失活），未被置为 0 的进行缩放，缩放比例为 1/(1-p)。训练过程可以认为是对完整神经网络的一些子集进行训练，每次基于输入数据只更新子网络的参数。
- 在测试过程中，随机失活不起作用。

![[Pasted image 20250505000309.png]]

### 4.3 BN 层

批量归一化（Batch Normalization），在计算机视觉领域使用较多。

先对数据标准化，再对数据重构（缩放 + 平移），如下所示：

$$
f(x) = \lambda \cdot \frac{x - E(x)}{\sqrt{\text{Var}(x)} + \epsilon} + \beta
$$

1. $\lambda$ 和 $\beta$ 是可学习的参数，它相当于对标准化后的值做了一个线性变换，$\lambda$ 为系数，$\beta$ 为偏置；
2. $\epsilon$ 通常指为 1e-5，避免分母为 0；
3. $E (x)$ 表示变量的均值；
4. $Var (x)$ 表示变量的方差；

![[Pasted image 20250505000618.png]]

## 5 案例 - 价格分类案例

1. 掌握构建分类模型流程
2. 动手实践整个过程

### 5.1 需求分析

![[Pasted image 20250505001647.png]]

![[Pasted image 20250505001707.png]]

### 5.2 xxx

### 5.3 调优

我们前面的网络模型在测试集的准确率为：

我们可以通过以下方面进行调优：

1. 优化方法由 SGD 调整为 Adam
2. 学习率由 1e-3 调整为 1e-4
3. 对数据进行标准化
4. 增加网络深度，即增加网络参数量
5. 调整训练轮次
6. 等
